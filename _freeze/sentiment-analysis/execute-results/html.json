{
  "hash": "30c39bedc59561a1b8043861370cd828",
  "result": {
    "markdown": "# Sentiment Analysis\n\n\n\n\n\n::: {.panel-tabset}\n\n## Conducting the analysis\n\n\n::: {.cell hash='sentiment-analysis_cache/html/sentiment analysis function_58880f87d723f15ebff3aa822b63dfd3'}\n\n```{.r .cell-code}\nconduct_sentiment_analysis <- function(sr = \"Python\", year = 2014){\n  input_directory <- paste0(\"/scratch1/tsranso/reddit/subreddit-posts/\", sr, \"/\", year)\n  \n  message(\"Opening input directory: \", input_directory)\n  posts <- spark_read_json(sc, path = input_directory, memory = FALSE)\n  message(\"Running analysis...\")\n  # sentiments <- posts %>% \n  #   collect() %>% \n  #   dplyr::mutate(dialogue_split = sentimentr::get_sentences(selftext), sub = sr) %$%\n  #   sentiment_by(dialogue_split, sub)\n  \nsentiments <- posts %>% \n    collect() %>% \n    sentimentr::get_sentences() %$%\n    sentiment_by(selftext)\n  \n  message(\"Computed sentiments for subreddit: \", sr, \" during \", year)\n  return(sentiments)\n}\n```\n:::\n\n\n## Plotting the results\n\n::: {.cell hash='sentiment-analysis_cache/html/sentiment plotting function_9b0beb1da6f6cd192717d5e4cfa704fd'}\n\n```{.r .cell-code}\nplot_sentiments <- function(sentiments, sr = \"Python\", year = 2014) {\n  plot <- ggplot(sentiments, aes(ave_sentiment, sr)) + \n    geom_boxplot()\n  ggsave(filename = paste0(\"sentiments-\", sr, \"-\", year, \".png\"), plot, path = \"plots/\")\n}\n#sr <- \"Python\"\n#year <- 2014\n#python_2014_sentiments <- conduct_sentiment_analysis()\n#plot_sentiments(python_2014_sentiments)\n```\n:::\n\n\n:::\n\n## Executing the analysis\n\n\n::: {.cell hash='sentiment-analysis_cache/html/sentiment analysis_e51abbb1f128d26fb195ce58819f6d38'}\n\n```{.r .cell-code}\nsubs_of_interest <- c(\"learnpython\",\n                      \"Python\",\n                      \"learnprogramming\",\n                      \"programming\",\n                      \"AskProgramming\",\n                      \"CSEducation\",\n                      \"computerscience\",\n                      \"AskComputerScience\",\n                      \"compsci\",\n                      \"AskCompSci\",\n                      \"cscareerquestions\",\n                      \"coding\",\n                      \"javascript\",\n                      \"learnjavascript\",\n                      \"java\",\n                      \"learnjava\",\n                      \"haskell\",\n                      \"haskellquestions\",\n                      \"C_Programming\")\nyears <- c(2014, 2015, 2016, 2017)\n\nfor (sub in subs_of_interest) {\n  for (y in years) {\n    if (!file.exists(paste0(\"data/sentiments-\", sub, \"-\", y, \".rds\"))) {\n      tryCatch({\n        withTimeout({\n          sentiments <- conduct_sentiment_analysis(sr = sub, year = y)\n          plot_sentiments(sentiments, sr = sub, year = y)\n          write_rds(sentiments, file = paste0(\"data/sentiments-\", sub, \"-\", y, \".rds\"))\n        }, timeout = 600)\n      }, TimeoutException = function(ex) {\n        message(\"Processing \", sub, \" \", y, \" timed out :(\")\n      })\n    } else { message(\"Already processed \", sub, \" \", y)}\n  }\n}\n```\n:::\n\n\n## Display some plots\n\n::: {.panel-tabset}\n\nHere is a huge amount of data to click through... each tab here has 2-3 subreddits I want to compare sentiments between. Chi-square tests are used to make comparisons between pairs and anovas are used for the triplets.\n\nInterpretation of these statistical tests needs some special attention here. Because of the size of the data sets that went into making these sentiments, this is really overpowered data. \n\n### [r/Python r/learnPython]\n\n\n::: {.cell hash='sentiment-analysis_cache/html/unnamed-chunk-1_012a4e7bd0386a7a5241882ab05d92b2'}\n\n```{.r .cell-code}\nlibrary(ggpubr)\n\nfor (year in 2014:2017) {\n  assign(paste0(\"sentiments-python-\", year), \n         readRDS(paste0(\"data/sentiments-Python-\", year, \".rds\")))\n  assign(paste0(\"sentiments-learnpython-\", year), \n         readRDS(paste0(\"data/sentiments-learnpython-\", year, \".rds\")))\n}\n\n`sentiments-learnpython-2014` %<>% select(ave_sentiment) %>% mutate(year = 2014)\n`sentiments-learnpython-2015` %<>% select(ave_sentiment) %>% mutate(year = 2015)\n`sentiments-learnpython-2016` %<>% select(ave_sentiment) %>% mutate(year = 2016)\n`sentiments-learnpython-2017` %<>% select(ave_sentiment) %>% mutate(year = 2017)\n\n`sentiments-python-2014` %<>% select(ave_sentiment) %>% mutate(year = 2014)\n`sentiments-python-2015` %<>% select(ave_sentiment) %>% mutate(year = 2015)\n`sentiments-python-2016` %<>% select(ave_sentiment) %>% mutate(year = 2016)\n`sentiments-python-2017` %<>% select(ave_sentiment) %>% mutate(year = 2017)\n\np_sentiments <- rbind(`sentiments-python-2014`, \n      `sentiments-python-2015`, \n      `sentiments-python-2016`, \n      `sentiments-python-2017`) \np_sentiments %>% ggboxplot(x = \"year\", y = \"ave_sentiment\")\n```\n\n::: {.cell-output-display}\n![](sentiment-analysis_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\np_sentiments %>% ggviolin(x = \"year\", y = \"ave_sentiment\")\n```\n\n::: {.cell-output-display}\n![](sentiment-analysis_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\np_sentiments %>% group_by(year) %>% summarise(avg = mean(ave_sentiment))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 2\n   year   avg\n  <dbl> <dbl>\n1  2014 0.184\n2  2015 0.151\n3  2016 0.110\n4  2017 0.108\n```\n:::\n\n```{.r .cell-code}\none.way <- aov(year ~ ave_sentiment, data = p_sentiments)\nsummary(one.way)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Df Sum Sq Mean Sq F value Pr(>F)    \nave_sentiment     1    261  261.18   232.7 <2e-16 ***\nResiduals     21701  24361    1.12                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nlp_sentiments <- rbind(`sentiments-learnpython-2014`, \n      `sentiments-learnpython-2015`, \n      `sentiments-learnpython-2016`, \n      `sentiments-learnpython-2017`) \nlp_sentiments %>% ggboxplot(x = \"year\", y = \"ave_sentiment\")\n```\n\n::: {.cell-output-display}\n![](sentiment-analysis_files/figure-html/unnamed-chunk-1-3.png){width=672}\n:::\n\n```{.r .cell-code}\nlp_sentiments %>% ggviolin(x = \"year\", y = \"ave_sentiment\")\n```\n\n::: {.cell-output-display}\n![](sentiment-analysis_files/figure-html/unnamed-chunk-1-4.png){width=672}\n:::\n\n```{.r .cell-code}\nlp_sentiments %>% group_by(year) %>% summarise(avg = mean(ave_sentiment))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 2\n   year    avg\n  <dbl>  <dbl>\n1  2014 0.117 \n2  2015 0.102 \n3  2016 0.0917\n4  2017 0.0919\n```\n:::\n\n```{.r .cell-code}\none.way <- aov(year ~ ave_sentiment, data = lp_sentiments)\nsummary(one.way)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Df Sum Sq Mean Sq F value   Pr(>F)    \nave_sentiment     1     62   61.94   58.22 2.38e-14 ***\nResiduals     62421  66406    1.06                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n### [r/java r/learnjava]\n\n### [r/javascript r/learnjavascript]\n\n### [r/programming r/learnprogramming r/AskProgramming]\n\n### [r/computerscience r/AskComputerScience]\n\n### [r/compsci r/AskCompSci]\n\n### [r/programming r/coding]\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}